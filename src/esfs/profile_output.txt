Timer unit: 1e-09 s

Total time: 0.15243 s
File: /Users/shandc/Documents/ESFS/ESFS/ESFS.py
Function: Create_Scaled_Matrix at line 38

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    38                                           @profile
    39                                           def Create_Scaled_Matrix(adata, clip_percentile=97.5, log_scale=False):
    40                                               """
    41                                               Prior to calculates ES metrics, the data will be scaled to have values
    42                                               between 0 and 1.
    43                                               """
    44                                               # Filter genes with no expression
    45         1    8215000.0    8e+06      5.4      Keep_Genes = Keep_Genes = adata.var_names[np.where(adata.X.getnnz(axis=0) > 50)[0]]
    46         1      10000.0  10000.0      0.0      if Keep_Genes.shape[0] < adata.shape[1]:
    47         2      24000.0  12000.0      0.0          print(
    48         2       5000.0   2500.0      0.0              str(adata.shape[1] - Keep_Genes.shape[0])
    49         1          0.0      0.0      0.0              + " genes show no expression. Removing them from adata object"
    50                                                   )
    51         1    1493000.0    1e+06      1.0          adata = adata[:, Keep_Genes]
    52                                               # Un-sparsify the data for clipping and scaling
    53         1    8055000.0    8e+06      5.3      Scaled_Expressions = adata.X.copy()
    54         1       2000.0   2000.0      0.0      if issparse(Scaled_Expressions) == True:
    55         1    2787000.0    3e+06      1.8          Scaled_Expressions = np.asarray(Scaled_Expressions.todense())
    56                                               # Log scale the data if user requests.
    57         1       1000.0   1000.0      0.0      if log_scale == True:
    58                                                   Scaled_Expressions = np.log2(Scaled_Expressions + 1)
    59                                               # Clip exceptionally high gene expression for each gene. Default percentile is the 97.5th.
    60         1   59088000.0    6e+07     38.8      Upper = np.percentile(Scaled_Expressions, clip_percentile, axis=0)
    61         2     532000.0 266000.0      0.3      Upper[np.where(Upper == 0)[0]] = np.max(Scaled_Expressions, axis=0)[
    62         1      12000.0  12000.0      0.0          np.where(Upper == 0)[0]
    63                                               ]
    64         1    5354000.0    5e+06      3.5      Scaled_Expressions = Scaled_Expressions.clip(max=Upper[None, :])
    65                                               # Normalise gene expression between 0 and 1.
    66         1    5463000.0    5e+06      3.6      Scaled_Expressions = Scaled_Expressions / Upper
    67                                               # Return data as a sparse csc_matrix
    68         1   61373000.0    6e+07     40.3      adata.layers["Scaled_Counts"] = csc_matrix(Scaled_Expressions.astype("f"))
    69         2      15000.0   7500.0      0.0      print(
    70         1          0.0      0.0      0.0          "Scaled expression matrix has been saved to 'adata.layers['Scaled_Counts']' as a sparse csc_matrix"
    71                                               )
    72         1       1000.0   1000.0      0.0      return adata

Total time: 2.68628 s
File: /Users/shandc/Documents/ESFS/ESFS/ESFS.py
Function: ESE2 at line 853

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   853                                           @profile
   854                                           def ESE2(x, SD, RFm, RFM, QFm, QFM, Ts):
   855                                               """
   856                                               This function takes the observed inputs and uses the ESE2 formulation of ES to caclulate the observed Conditional Entropy (CE),
   857                                               Independent Entropy (Ind_E) and Minimum Entropy (Min_E).
   858                                               """
   859     18128   71966000.0   3969.9      2.7      G1_E = (RFm / Ts) * (
   860                                                   (
   861     18128  280440000.0  15470.0     10.4              -(((RFm - x) / RFm) * np.log((RFm - x) / RFm))
   862      9064  253441000.0  27961.3      9.4              - (((x) / RFm) * np.log((x) / RFm))
   863                                                   )
   864                                               )
   865     18128   45402000.0   2504.5      1.7      G2_E = (RFM / Ts) * (
   866                                                   (
   867     18128  287752000.0  15873.3     10.7              -(((RFM - QFM + x) / RFM) * np.log((RFM - QFM + x) / RFM))
   868      9064  235857000.0  26021.3      8.8              - (((QFM - x) / RFM) * np.log((QFM - x) / RFM))
   869                                                   )
   870                                               )
   871      9064  106673000.0  11768.9      4.0      CE = np.where(np.isnan(G1_E), 0, G1_E) + np.where(np.isnan(G2_E), 0, G2_E)
   872      9064  281599000.0  31067.9     10.5      Ind_E = (QFm / Ts) * (-np.log((QFm / Ts))) + (QFM / Ts) * (-np.log((QFM / Ts)))
   873                                               #
   874      9064    9825000.0   1084.0      0.4      Min_E = np.zeros(SD.shape[0])
   875      9064   53475000.0   5899.7      2.0      SD_1_Inds = np.where(SD == -1)[0]
   876     18128  102086000.0   5631.4      3.8      Min_E[SD_1_Inds] = (RFM[SD_1_Inds] / Ts) * (
   877                                                   (
   878     18128   16088000.0    887.5      0.6              -(
   879     18128   99008000.0   5461.6      3.7                  ((RFM[SD_1_Inds] - QFM[SD_1_Inds]) / RFM[SD_1_Inds])
   880      9064  150687000.0  16624.8      5.6                  * np.log((RFM[SD_1_Inds] - QFM[SD_1_Inds]) / RFM[SD_1_Inds])
   881                                                       )
   882                                                       - (
   883     18128   62453000.0   3445.1      2.3                  ((QFM[SD_1_Inds]) / RFM[SD_1_Inds])
   884      9064  123346000.0  13608.3      4.6                  * np.log((QFM[SD_1_Inds]) / RFM[SD_1_Inds])
   885                                                       )
   886                                                   )
   887                                               )
   888      9064   53839000.0   5939.9      2.0      SD1_Inds = np.where(SD == 1)[0]
   889     18128   63585000.0   3507.6      2.4      Min_E[SD1_Inds] = (RFM[SD1_Inds] / Ts) * (
   890                                                   (
   891     18128   12250000.0    675.8      0.5              -(
   892     18128   71426000.0   3940.1      2.7                  ((RFM[SD1_Inds] - QFM[SD1_Inds] + RFm[SD1_Inds]) / RFM[SD1_Inds])
   893     18128   35352000.0   1950.1      1.3                  * np.log(
   894      9064   59992000.0   6618.7      2.2                      (RFM[SD1_Inds] - QFM[SD1_Inds] + RFm[SD1_Inds]) / RFM[SD1_Inds]
   895                                                           )
   896                                                       )
   897                                                       - (
   898     18128   50542000.0   2788.1      1.9                  ((QFM[SD1_Inds] - RFm[SD1_Inds]) / RFM[SD1_Inds])
   899      9064  102774000.0  11338.7      3.8                  * np.log((QFM[SD1_Inds] - RFm[SD1_Inds]) / RFM[SD1_Inds])
   900                                                       )
   901                                                   )
   902                                               )
   903      9064   19194000.0   2117.6      0.7      Min_E[np.isnan(Min_E)] = 0
   904                                               #
   905      9064   23410000.0   2582.7      0.9      CE[np.isnan(CE)] = Min_E[np.isnan(CE)]
   906      9064   13821000.0   1524.8      0.5      return CE, Ind_E, Min_E

Total time: 2.72177 s
File: /Users/shandc/Documents/ESFS/ESFS/ESFS.py
Function: ESE3 at line 909

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   909                                           @profile
   910                                           def ESE3(x, SD, RFm, RFM, QFm, QFM, Ts, Min_Overlap):
   911                                               """
   912                                               This function takes the observed inputs and uses the ESE3 formulation of ES to caclulate the observed Conditional Entropy (CE),
   913                                               Independent Entropy (Ind_E) and Minimum Entropy (Min_E).
   914                                               """
   915     18130   49401000.0   2724.8      1.8      G1_E = (RFm / Ts) * (
   916                                                   (
   917     18130  279816000.0  15433.9     10.3              -(((QFm - x) / RFm) * np.log((QFm - x) / RFm))
   918      9065  335516000.0  37012.2     12.3              - (((RFm - QFm + x) / RFm) * np.log((RFm - QFm + x) / RFm))
   919                                                   )
   920                                               )
   921     18130   49876000.0   2751.0      1.8      G2_E = (RFM / Ts) * (
   922                                                   (
   923     18130  219950000.0  12131.8      8.1              -(((x) / RFM) * np.log((x) / RFM))
   924      9065  257249000.0  28378.3      9.5              - (((RFM - x) / RFM) * np.log((RFM - x) / RFM))
   925                                                   )
   926                                               )
   927      9065  110072000.0  12142.5      4.0      CE = np.where(np.isnan(G1_E), 0, G1_E) + np.where(np.isnan(G2_E), 0, G2_E)
   928      9065  289214000.0  31904.5     10.6      Ind_E = (QFm / Ts) * (-np.log((QFm / Ts))) + (QFM / Ts) * (-np.log((QFM / Ts)))
   929                                               #
   930      9065    9163000.0   1010.8      0.3      Min_E = np.zeros(SD.shape[0])
   931      9065   56269000.0   6207.3      2.1      SD_1_Inds = np.where(SD == -1)[0]
   932     18130  109750000.0   6053.5      4.0      Min_E[SD_1_Inds] = (RFM[SD_1_Inds] / Ts) * (
   933                                                   (
   934     18130   15383000.0    848.5      0.6              -(
   935     18130   71799000.0   3960.2      2.6                  ((Min_Overlap[SD_1_Inds]) / RFM[SD_1_Inds])
   936      9065  126350000.0  13938.2      4.6                  * np.log((Min_Overlap[SD_1_Inds]) / RFM[SD_1_Inds])
   937                                                       )
   938                                                       - (
   939     18130   99801000.0   5504.7      3.7                  ((RFM[SD_1_Inds] - Min_Overlap[SD_1_Inds]) / RFM[SD_1_Inds])
   940      9065  154185000.0  17008.8      5.7                  * np.log((RFM[SD_1_Inds] - Min_Overlap[SD_1_Inds]) / RFM[SD_1_Inds])
   941                                                       )
   942                                                   )
   943                                               )
   944      9065   47364000.0   5224.9      1.7      SD1_Inds = np.where(SD == 1)[0]
   945     18130   61143000.0   3372.5      2.2      Min_E[SD1_Inds] = (RFM[SD1_Inds] / Ts) * (
   946                                                   (
   947     18130   11671000.0    643.7      0.4              -(
   948     18130   74120000.0   4088.3      2.7                  ((RFM[SD1_Inds] - QFM[SD1_Inds] + RFm[SD1_Inds]) / RFM[SD1_Inds])
   949     18130   38181000.0   2106.0      1.4                  * np.log(
   950      9065   63380000.0   6991.7      2.3                      (RFM[SD1_Inds] - QFM[SD1_Inds] + RFm[SD1_Inds]) / RFM[SD1_Inds]
   951                                                           )
   952                                                       )
   953                                                       - (
   954     18130   50090000.0   2762.8      1.8                  ((QFM[SD1_Inds] - RFm[SD1_Inds]) / RFM[SD1_Inds])
   955      9065   79097000.0   8725.5      2.9                  * np.log((QFM[SD1_Inds] - RFm[SD1_Inds]) / RFM[SD1_Inds])
   956                                                       )
   957                                                   )
   958                                               )
   959      9065   27437000.0   3026.7      1.0      Min_E[np.isnan(Min_E)] = 0
   960                                               #
   961      9065   23150000.0   2553.8      0.9      CE[np.isnan(CE)] = Min_E[np.isnan(CE)]
   962      9065   12346000.0   1361.9      0.5      return CE, Ind_E, Min_E

Total time: 5.5555 s
File: /Users/shandc/Documents/ESFS/ESFS/ESFS.py
Function: ESE1 at line 801

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   801                                           @profile
   802                                           def ESE1(x, SD, RFm, RFM, QFm, QFM, Ts, Max_Overlap):
   803                                               """
   804                                               This function takes the observed inputs and uses the ESE1 formulation of ES to caclulate the observed Conditional Entropy (CE),
   805                                               Independent Entropy (Ind_E) and Minimum Entropy (Min_E).
   806                                               """
   807     18130   87989000.0   4853.2      1.6      G1_E = (RFm / Ts) * (
   808     18130  493193000.0  27203.1      8.9          (((x) / RFm) * (-np.log((x) / RFm)))
   809      9065  592591000.0  65371.3     10.7          + (((RFm - x) / RFm) * (-np.log((RFm - x) / RFm)))
   810                                               )
   811     18130   70831000.0   3906.8      1.3      G2_E = (RFM / Ts) * (
   812     18130  535027000.0  29510.6      9.6          (((QFm - x) / RFM) * (-np.log((QFm - x) / RFM)))
   813      9065  572564000.0  63162.1     10.3          + (((RFM - QFm + x) / RFM) * (-np.log((RFM - QFm + x) / RFM)))
   814                                               )
   815      9065  269592000.0  29739.9      4.9      CE = np.where(np.isnan(G1_E), 0, G1_E) + np.where(np.isnan(G2_E), 0, G2_E)
   816      9065  545279000.0  60152.1      9.8      Ind_E = (QFm / Ts) * (-np.log((QFm / Ts))) + (QFM / Ts) * (-np.log((QFM / Ts)))
   817                                               #
   818      9065   16323000.0   1800.7      0.3      Min_E = np.zeros(SD.shape[0])
   819      9065   56880000.0   6274.7      1.0      SD_1_Inds = np.where(SD == -1)[0]
   820     18130   35193000.0   1941.1      0.6      Min_E[SD_1_Inds] = (RFM[SD_1_Inds] / Ts) * (
   821      9065    4675000.0    515.7      0.1          (
   822     18130   20635000.0   1138.2      0.4              ((QFm[SD_1_Inds]) / RFM[SD_1_Inds])
   823      9065   18115000.0   1998.3      0.3              * (-np.log((QFm[SD_1_Inds]) / RFM[SD_1_Inds]))
   824                                                   )
   825                                                   + (
   826     18130   19073000.0   1052.0      0.3              ((RFM[SD_1_Inds] - QFm[SD_1_Inds]) / RFM[SD_1_Inds])
   827      9065   20059000.0   2212.8      0.4              * (-np.log((RFM[SD_1_Inds] - QFm[SD_1_Inds]) / RFM[SD_1_Inds]))
   828                                                   )
   829                                               )
   830      9065   92001000.0  10149.0      1.7      SD1_Inds = np.where(SD == 1)[0]
   831     18130  312289000.0  17225.0      5.6      Min_E[SD1_Inds] = (RFM[SD1_Inds] / Ts) * (
   832      9065   16539000.0   1824.5      0.3          (
   833     18130  298580000.0  16468.8      5.4              ((QFm[SD1_Inds] - Max_Overlap[SD1_Inds]) / RFM[SD1_Inds])
   834      9065  471122000.0  51971.5      8.5              * (-np.log((QFm[SD1_Inds] - Max_Overlap[SD1_Inds]) / RFM[SD1_Inds]))
   835                                                   )
   836                                                   + (
   837     18130  363265000.0  20036.7      6.5              ((RFM[SD1_Inds] - QFm[SD1_Inds] + Max_Overlap[SD1_Inds]) / RFM[SD1_Inds])
   838                                                       * (
   839     18130  200408000.0  11053.9      3.6                  -np.log(
   840     18130  266394000.0  14693.5      4.8                      (RFM[SD1_Inds] - QFm[SD1_Inds] + Max_Overlap[SD1_Inds])
   841      9065   61356000.0   6768.5      1.1                      / RFM[SD1_Inds]
   842                                                           )
   843                                                       )
   844                                                   )
   845                                               )
   846      9065   42496000.0   4687.9      0.8      Min_E[np.isnan(Min_E)] = 0
   847      9065   17728000.0   1955.7      0.3      Min_E[np.isnan(Min_E)] = 0
   848                                               #
   849      9065   39496000.0   4357.0      0.7      CE[np.isnan(CE)] = Min_E[np.isnan(CE)]
   850      9065   15802000.0   1743.2      0.3      return CE, Ind_E, Min_E

Total time: 7.3157 s
File: /Users/shandc/Documents/ESFS/ESFS/ESFS.py
Function: nanmaximum at line 233

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   233                                           @profile
   234                                           def nanmaximum(arr1, arr2):
   235                                               """
   236                                               Element-wise maximum of two arrays, ignoring NaN values and converting inf to -inf.
   237                                           
   238                                               Parameters:
   239                                                   arr1 (ndarray): First input array.
   240                                                   arr2 (ndarray): Second input array.
   241                                           
   242                                               Returns:
   243                                                   ndarray: Element-wise maximum of arr1 and arr2, ignoring NaN values.
   244                                               """
   245                                               # Replace all inf and -inf values with -inf for both arrays
   246      9067  947603000.0 104511.2     13.0      arr1 = np.where(np.isinf(arr1), -np.inf, arr1)
   247      9067  404114000.0  44569.8      5.5      arr2 = np.where(np.isinf(arr2), -np.inf, arr2)
   248                                               # Replace NaN values with -infinity for comparison
   249      9067  541908000.0  59767.1      7.4      arr1_nan = np.where(np.isnan(arr1), -np.inf, arr1)
   250      9067 1217497000.0 134277.8     16.6      arr2_nan = np.where(np.isnan(arr2), -np.inf, arr2)
   251                                               # Compute the element-wise maximum
   252      9067 2051449000.0 226254.4     28.0      result = np.maximum(arr1_nan, arr2_nan)
   253                                               # Where both values are NaN, the result should be NaN
   254      9067 2111033000.0 232826.0     28.9      nan_mask = np.isnan(arr1) & np.isnan(arr2)
   255      9067   36701000.0   4047.8      0.5      result[nan_mask] = np.nan
   256      9067    5395000.0    595.0      0.1      return result

Total time: 27.0036 s
File: /Users/shandc/Documents/ESFS/ESFS/ESFS.py
Function: Calc_ESSs at line 484

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   484                                           @profile
   485                                           def Calc_ESSs(
   486                                               RFms,
   487                                               QFms,
   488                                               RFMs,
   489                                               QFMs,
   490                                               Max_Ent_Options,
   491                                               Sample_Cardinality,
   492                                               All_Overlaps_Options,
   493                                               All_Use_Cases,
   494                                               All_Used_Inds,
   495                                           ):
   496                                               """
   497                                               Now that we have all of the values required for ES caclulations (RFms, QFms, RFMs, QFMs, Max_Ent_Options) and
   498                                               have determined which ESE should be used for each pair of features (All_Overlaps_Options, All_Use_Cases, All_Used_Inds),
   499                                               we may calculated the ES metrics for the FF against every other feature in adata.
   500                                               """
   501                                               ## Create variables to track caclulation outputs
   502      9065   44717000.0   4932.9      0.2      All_ESSs = np.zeros((4, RFms.shape[0]))
   503      9065   41845000.0   4616.1      0.2      All_D_EPs = np.zeros((4, RFms.shape[0]))
   504      9065   41041000.0   4527.4      0.2      All_O_EPs = np.zeros((4, RFms.shape[0]))
   505      9065   44536000.0   4913.0      0.2      All_SGs = np.zeros((4, RFms.shape[0]))
   506      9065   67752000.0   7474.0      0.3      All_SWs = np.zeros((4, RFms.shape[0]))
   507                                               ###################
   508                                               ##### (1)  mm #####
   509      9065    2230000.0    246.0      0.0      Use_Curve = 0
   510                                               ## Find the FF/SF pairs where we should use ESE (1) to calculate entropies
   511      9065   27170000.0   2997.2      0.1      Calc_Inds = All_Used_Inds[Use_Curve].astype("i")
   512      9065    2993000.0    330.2      0.0      if Calc_Inds.shape[0] > 0:
   513                                                   # Retrieve the Max_Ent, Min_x, Max_X and observed overlap values
   514      9065  113758000.0  12549.1      0.4          Min_Overlap = np.repeat(0, Calc_Inds.shape[0])
   515      9065  145830000.0  16087.1      0.5          Max_Overlap = RFms[Calc_Inds]
   516      9065  123351000.0  13607.4      0.5          Overlaps = All_Overlaps_Options[Use_Curve, Calc_Inds]
   517      9065  163598000.0  18047.2      0.6          Max_Ent_x = Max_Ent_Options[Use_Curve, Calc_Inds]
   518      9065  111902000.0  12344.4      0.4          Ind_X_1 = Max_Ent_x - Min_Overlap
   519      9065   20492000.0   2260.6      0.1          Ind_X1 = Max_Overlap - Max_Ent_x
   520                                                   #
   521      9065  105377000.0  11624.6      0.4          SD_1_Inds = np.where(Overlaps < Max_Ent_x)[0]
   522      9065  121068000.0  13355.5      0.4          SD1_Inds = np.where(Overlaps >= Max_Ent_x)[0]
   523      9065   66642000.0   7351.6      0.2          SDs = np.zeros(Calc_Inds.shape[0]) - 1
   524      9065   92658000.0  10221.5      0.3          SDs[SD1_Inds] = 1
   525                                                   #
   526      9065   20624000.0   2275.1      0.1          D = np.zeros(Calc_Inds.shape[0])
   527      9065   24982000.0   2755.9      0.1          O = np.zeros(Calc_Inds.shape[0])
   528      9065   10513000.0   1159.7      0.0          D[SD_1_Inds] = Overlaps[SD_1_Inds]
   529      9065    6022000.0    664.3      0.0          O[SD_1_Inds] = (
   530     27195   37247000.0   1369.6      0.1              Sample_Cardinality
   531      9065  260349000.0  28720.2      1.0              - (RFms[Calc_Inds][SD_1_Inds] + QFms[Calc_Inds][SD_1_Inds])
   532      9065    3325000.0    366.8      0.0              + Overlaps[SD_1_Inds]
   533                                                   )
   534      9065  394813000.0  43553.6      1.5          D[SD1_Inds] = RFms[Calc_Inds][SD1_Inds] - Overlaps[SD1_Inds]
   535      9065  529176000.0  58375.7      2.0          O[SD1_Inds] = QFms[Calc_Inds][SD1_Inds] - Overlaps[SD1_Inds]
   536                                                   # Perform caclulations with ESE (1)
   537     18130 5884462000.0 324570.4     21.8          CE, Ind_E, Min_E = ESE1(
   538      9065    2000000.0    220.6      0.0              Overlaps,
   539      9065    2032000.0    224.2      0.0              SDs,
   540      9065  305358000.0  33685.4      1.1              RFms[Calc_Inds],
   541      9065  134510000.0  14838.4      0.5              RFMs[Calc_Inds],
   542      9065  114433000.0  12623.6      0.4              QFms[Calc_Inds],
   543      9065  119411000.0  13172.8      0.4              QFMs[Calc_Inds],
   544      9065    1353000.0    149.3      0.0              Sample_Cardinality,
   545      9065    1123000.0    123.9      0.0              Max_Overlap,
   546                                                   )
   547                                                   #
   548      9065  106992000.0  11802.8      0.4          SWs = (Ind_E - Min_E) / Ind_E
   549      9065  166252000.0  18340.0      0.6          SGs = (Ind_E - CE) / (Ind_E - Min_E)
   550                                                   # Because of float errors the following inequality at the boundary sometimes fails, (CE[Test] < Min_E[Test]), leading to values greater than 1. It is valid to just correct them to 1.
   551      9065   38096000.0   4202.5      0.1          SGs[SGs > 1] = 1
   552                                                   # Because of float errors the following inequality at the maximum sometimes fails, (CE[Test] > Ind_E[Test]), leading to values greater than less than 0. It is valid to just correct them to 0.
   553      9065   26205000.0   2890.8      0.1          SGs[SGs < 0] = 0
   554                                                   #
   555      9065  208516000.0  23002.3      0.8          ESS = SWs * SGs * SDs * All_Use_Cases[Use_Curve, Calc_Inds]
   556      9065  199079000.0  21961.3      0.7          All_ESSs[Use_Curve, Calc_Inds] = ESS
   557      9065  155057000.0  17105.0      0.6          All_SWs[Use_Curve, Calc_Inds] = SWs
   558      9065  161821000.0  17851.2      0.6          All_SGs[Use_Curve, Calc_Inds] = SGs
   559                                                   #
   560      9065   22132000.0   2441.5      0.1          SD_1_IndEnt = Ind_E[SD_1_Inds] / Ind_X_1[SD_1_Inds]
   561      9065  145772000.0  16080.8      0.5          SD1_IndEnt = Ind_E[SD1_Inds] / Ind_X1[SD1_Inds]
   562                                                   #
   563      9065   20455000.0   2256.5      0.1          D_EPs = np.zeros(Ind_E.shape[0])
   564      9065    7755000.0    855.5      0.0          D_EPs[SD_1_Inds] = (
   565      9065   19185000.0   2116.4      0.1              (CE[SD_1_Inds] - Min_E[SD_1_Inds]) / D[SD_1_Inds]
   566      9065    2648000.0    292.1      0.0          ) - SD_1_IndEnt
   567      9065  533949000.0  58902.3      2.0          D_EPs[SD1_Inds] = ((CE[SD1_Inds] - Min_E[SD1_Inds]) / D[SD1_Inds]) - SD1_IndEnt
   568                                                   #
   569      9065   26345000.0   2906.2      0.1          O_EPs = np.zeros(Ind_E.shape[0])
   570      9065   16213000.0   1788.5      0.1          O_EPs[SD_1_Inds] = ((CE[SD_1_Inds]) / O[SD_1_Inds]) - SD_1_IndEnt
   571      9065  446167000.0  49218.6      1.7          O_EPs[SD1_Inds] = ((CE[SD1_Inds]) / O[SD1_Inds]) - SD1_IndEnt
   572                                                   #
   573      9065  155763000.0  17182.9      0.6          All_D_EPs[Use_Curve, Calc_Inds] = D_EPs
   574      9065  152598000.0  16833.8      0.6          All_O_EPs[Use_Curve, Calc_Inds] = O_EPs
   575                                                   #
   576                                               ###################
   577                                               ##### (2)  Mm #####
   578      9065    3311000.0    365.3      0.0      Use_Curve = 1
   579                                               ## Find the FF/SF pairs where we should use ESE (2) to calculate entropies
   580      9065   22250000.0   2454.5      0.1      Calc_Inds = All_Used_Inds[Use_Curve].astype("i")
   581      9065    5347000.0    589.9      0.0      if Calc_Inds.shape[0] > 0:
   582                                                   # Retrieve the Max_Ent, Min_x, Max_X and observed overlap values
   583      9064  104867000.0  11569.6      0.4          Min_Overlap = np.repeat(0, Calc_Inds.shape[0])
   584      9064  144061000.0  15893.8      0.5          Max_Overlap = np.minimum(RFms[Calc_Inds], QFMs[Calc_Inds])
   585      9064   71059000.0   7839.7      0.3          Overlaps = All_Overlaps_Options[Use_Curve, Calc_Inds]
   586      9064   64048000.0   7066.2      0.2          Max_Ent_x = Max_Ent_Options[Use_Curve, Calc_Inds]
   587      9064   51355000.0   5665.8      0.2          Ind_X_1 = Max_Ent_x - Min_Overlap
   588      9064   16944000.0   1869.4      0.1          Ind_X1 = Max_Overlap - Max_Ent_x
   589                                                   #
   590      9064   67080000.0   7400.7      0.2          SD_1_Inds = np.where(Overlaps < Max_Ent_x)[0]
   591      9064   64128000.0   7075.0      0.2          SD1_Inds = np.where(Overlaps >= Max_Ent_x)[0]
   592      9064   41107000.0   4535.2      0.2          SDs = np.zeros(Calc_Inds.shape[0]) - 1
   593      9064   20245000.0   2233.6      0.1          SDs[SD1_Inds] = 1
   594                                                   #
   595      9064   11522000.0   1271.2      0.0          D = np.zeros(Calc_Inds.shape[0])
   596      9064    9534000.0   1051.9      0.0          O = np.zeros(Calc_Inds.shape[0])
   597      9064   58301000.0   6432.1      0.2          D[SD_1_Inds] = Overlaps[SD_1_Inds]
   598      9064   34384000.0   3793.5      0.1          O[SD_1_Inds] = (
   599     27192  141788000.0   5214.3      0.5              QFms[Calc_Inds][SD_1_Inds]
   600      9064   82612000.0   9114.3      0.3              - RFms[Calc_Inds][SD_1_Inds]
   601      9064   24605000.0   2714.6      0.1              + Overlaps[SD_1_Inds]
   602                                                   )
   603      9064  118846000.0  13111.9      0.4          D[SD1_Inds] = RFms[Calc_Inds][SD1_Inds] - Overlaps[SD1_Inds]
   604      9064   17509000.0   1931.7      0.1          O[SD1_Inds] = (
   605      9064  257640000.0  28424.5      1.0              QFMs[Calc_Inds][SD1_Inds] - RFms[Calc_Inds][SD1_Inds] + D[SD1_Inds]
   606                                                   )
   607                                                   # Perform caclulations with ESE (2)
   608     18128 2886203000.0 159212.4     10.7          CE, Ind_E, Min_E = ESE2(
   609      9064    5849000.0    645.3      0.0              Overlaps,
   610      9064    2520000.0    278.0      0.0              SDs,
   611      9064   58888000.0   6496.9      0.2              RFms[Calc_Inds],
   612      9064   68913000.0   7602.9      0.3              RFMs[Calc_Inds],
   613      9064   56784000.0   6264.8      0.2              QFms[Calc_Inds],
   614      9064   56594000.0   6243.8      0.2              QFMs[Calc_Inds],
   615      9064     993000.0    109.6      0.0              Sample_Cardinality,
   616                                                   )
   617                                                   #
   618      9064   56581000.0   6242.4      0.2          SWs = (Ind_E - Min_E) / Ind_E
   619      9064   65191000.0   7192.3      0.2          SGs = (Ind_E - CE) / (Ind_E - Min_E)
   620                                                   # Because of float errors the following inequality at the boundary sometimes fails, (CE[Test] < Min_E[Test]), leading to values greater than 1. It is valid to just correct them to 1.
   621      9064   23230000.0   2562.9      0.1          SGs[SGs > 1] = 1
   622                                                   # Because of float errors the following inequality at the maximum sometimes fails, (CE[Test] > Ind_E[Test]), leading to values greater than less than 0. It is valid to just correct them to 0.
   623      9064   25256000.0   2786.4      0.1          SGs[SGs < 0] = 0
   624                                                   #
   625      9064  112527000.0  12414.7      0.4          ESS = SWs * SGs * SDs * All_Use_Cases[Use_Curve, Calc_Inds]
   626      9064   88314000.0   9743.4      0.3          All_ESSs[Use_Curve, Calc_Inds] = ESS
   627      9064   82634000.0   9116.7      0.3          All_SWs[Use_Curve, Calc_Inds] = SWs
   628      9064   83756000.0   9240.5      0.3          All_SGs[Use_Curve, Calc_Inds] = SGs
   629                                                   #
   630      9064   71415000.0   7879.0      0.3          SD_1_IndEnt = Ind_E[SD_1_Inds] / Ind_X_1[SD_1_Inds]
   631      9064   33022000.0   3643.2      0.1          SD1_IndEnt = Ind_E[SD1_Inds] / Ind_X1[SD1_Inds]
   632                                                   #
   633      9064   11763000.0   1297.8      0.0          D_EPs = np.zeros(Ind_E.shape[0])
   634      9064   44952000.0   4959.4      0.2          D_EPs[SD_1_Inds] = (
   635      9064  128128000.0  14135.9      0.5              (CE[SD_1_Inds] - Min_E[SD_1_Inds]) / D[SD_1_Inds]
   636      9064    2988000.0    329.7      0.0          ) - SD_1_IndEnt
   637      9064   81106000.0   8948.1      0.3          D_EPs[SD1_Inds] = ((CE[SD1_Inds] - Min_E[SD1_Inds]) / D[SD1_Inds]) - SD1_IndEnt
   638                                                   #
   639      9064   13068000.0   1441.7      0.0          O_EPs = np.zeros(Ind_E.shape[0])
   640      9064  108051000.0  11920.9      0.4          O_EPs[SD_1_Inds] = ((CE[SD_1_Inds]) / O[SD_1_Inds]) - SD_1_IndEnt
   641      9064   60771000.0   6704.7      0.2          O_EPs[SD1_Inds] = ((CE[SD1_Inds]) / O[SD1_Inds]) - SD1_IndEnt
   642                                                   #
   643      9064   88059000.0   9715.2      0.3          All_D_EPs[Use_Curve, Calc_Inds] = D_EPs
   644      9064   86419000.0   9534.3      0.3          All_O_EPs[Use_Curve, Calc_Inds] = O_EPs
   645                                                   #
   646                                               ###################
   647                                               ##### (3)  mM #####
   648      9065    3586000.0    395.6      0.0      Use_Curve = 2
   649                                               ## Find the FF/SF pairs where we should use ESE (3) to calculate entropies
   650      9065   15780000.0   1740.8      0.1      Calc_Inds = All_Used_Inds[Use_Curve].astype("i")
   651      9065    2695000.0    297.3      0.0      if Calc_Inds.shape[0] > 0:
   652                                                   # Retrieve the Max_Ent, Min_x, Max_X and observed overlap values
   653      9065  143533000.0  15833.8      0.5          Min_Overlap = RFMs[Calc_Inds] - QFMs[Calc_Inds]
   654      9065  148258000.0  16355.0      0.5          Max_Overlap = np.minimum(QFms[Calc_Inds], RFMs[Calc_Inds])
   655      9065   68915000.0   7602.3      0.3          Overlaps = All_Overlaps_Options[Use_Curve, Calc_Inds]
   656      9065   63962000.0   7055.9      0.2          Max_Ent_x = Max_Ent_Options[Use_Curve, Calc_Inds]
   657      9065   12566000.0   1386.2      0.0          Ind_X_1 = Max_Ent_x - Min_Overlap
   658      9065   12729000.0   1404.2      0.0          Ind_X1 = Max_Overlap - Max_Ent_x
   659                                                   #
   660      9065   67738000.0   7472.5      0.3          SD_1_Inds = np.where(Overlaps < Max_Ent_x)[0]
   661      9065   59949000.0   6613.2      0.2          SD1_Inds = np.where(Overlaps >= Max_Ent_x)[0]
   662      9065   31565000.0   3482.1      0.1          SDs = np.zeros(Calc_Inds.shape[0]) - 1
   663      9065   21037000.0   2320.7      0.1          SDs[SD1_Inds] = 1
   664                                                   #
   665      9065   11555000.0   1274.7      0.0          D = np.zeros(Calc_Inds.shape[0])
   666      9065    9441000.0   1041.5      0.0          O = np.zeros(Calc_Inds.shape[0])
   667      9065   36122000.0   3984.8      0.1          D[SD_1_Inds] = (
   668     27195  135264000.0   4973.9      0.5              QFMs[Calc_Inds][SD_1_Inds]
   669      9065   81921000.0   9037.1      0.3              - RFMs[Calc_Inds][SD_1_Inds]
   670      9065   24466000.0   2699.0      0.1              + Overlaps[SD_1_Inds]
   671                                                   )
   672      9065   54892000.0   6055.4      0.2          O[SD_1_Inds] = Overlaps[SD_1_Inds]
   673      9065  124640000.0  13749.6      0.5          D[SD1_Inds] = QFms[Calc_Inds][SD1_Inds] - Overlaps[SD1_Inds]
   674      9065  107472000.0  11855.7      0.4          O[SD1_Inds] = RFMs[Calc_Inds][SD1_Inds] - Overlaps[SD1_Inds]
   675                                                   # Perform caclulations with ESE (3)
   676     18130 2892121000.0 159521.3     10.7          CE, Ind_E, Min_E = ESE3(
   677      9065    2082000.0    229.7      0.0              Overlaps,
   678      9065    1126000.0    124.2      0.0              SDs,
   679      9065   60488000.0   6672.7      0.2              RFms[Calc_Inds],
   680      9065   56943000.0   6281.6      0.2              RFMs[Calc_Inds],
   681      9065   59242000.0   6535.2      0.2              QFms[Calc_Inds],
   682      9065   62023000.0   6842.0      0.2              QFMs[Calc_Inds],
   683      9065    2643000.0    291.6      0.0              Sample_Cardinality,
   684      9065    1092000.0    120.5      0.0              Min_Overlap,
   685                                                   )
   686                                                   #
   687      9065   56236000.0   6203.6      0.2          SWs = (Ind_E - Min_E) / Ind_E
   688      9065   67211000.0   7414.3      0.2          SGs = (Ind_E - CE) / (Ind_E - Min_E)
   689                                                   # Because of float errors the following inequality at the boundary sometimes fails, (CE[Test] < Min_E[Test]), leading to values greater than 1. It is valid to just correct them to 1.
   690      9065   21938000.0   2420.1      0.1          SGs[SGs > 1] = 1
   691                                                   # Because of float errors the following inequality at the maximum sometimes fails, (CE[Test] > Ind_E[Test]), leading to values greater than less than 0. It is valid to just correct them to 0.
   692      9065   24962000.0   2753.7      0.1          SGs[SGs < 0] = 0
   693                                                   #
   694      9065  116891000.0  12894.8      0.4          ESS = SWs * SGs * SDs * All_Use_Cases[Use_Curve, Calc_Inds]
   695      9065   88598000.0   9773.6      0.3          All_ESSs[Use_Curve, Calc_Inds] = ESS
   696      9065   85818000.0   9467.0      0.3          All_SWs[Use_Curve, Calc_Inds] = SWs
   697      9065   83472000.0   9208.2      0.3          All_SGs[Use_Curve, Calc_Inds] = SGs
   698                                                   #
   699      9065   66076000.0   7289.1      0.2          SD_1_IndEnt = Ind_E[SD_1_Inds] / Ind_X_1[SD_1_Inds]
   700      9065   31332000.0   3456.4      0.1          SD1_IndEnt = Ind_E[SD1_Inds] / Ind_X1[SD1_Inds]
   701                                                   #
   702      9065   11624000.0   1282.3      0.0          D_EPs = np.zeros(Ind_E.shape[0])
   703      9065   58316000.0   6433.1      0.2          D_EPs[SD_1_Inds] = (
   704      9065  105641000.0  11653.7      0.4              (CE[SD_1_Inds] - Min_E[SD_1_Inds]) / D[SD_1_Inds]
   705      9065    2457000.0    271.0      0.0          ) - SD_1_IndEnt
   706      9065   77316000.0   8529.1      0.3          D_EPs[SD1_Inds] = ((CE[SD1_Inds] - Min_E[SD1_Inds]) / D[SD1_Inds]) - SD1_IndEnt
   707                                                   #
   708      9065   11166000.0   1231.8      0.0          O_EPs = np.zeros(Ind_E.shape[0])
   709      9065  113098000.0  12476.3      0.4          O_EPs[SD_1_Inds] = ((CE[SD_1_Inds]) / O[SD_1_Inds]) - SD_1_IndEnt
   710      9065   57630000.0   6357.4      0.2          O_EPs[SD1_Inds] = ((CE[SD1_Inds]) / O[SD1_Inds]) - SD1_IndEnt
   711                                                   #
   712      9065   85448000.0   9426.1      0.3          All_D_EPs[Use_Curve, Calc_Inds] = D_EPs
   713      9065   84959000.0   9372.2      0.3          All_O_EPs[Use_Curve, Calc_Inds] = O_EPs
   714                                                   #
   715                                               ###################
   716                                               ##### (4)  MM #####
   717      9065    2264000.0    249.8      0.0      Use_Curve = 3
   718                                               ## Find the FF/SF pairs where we should use ESE (4) to calculate entropies
   719      9065    8813000.0    972.2      0.0      Calc_Inds = All_Used_Inds[Use_Curve].astype("i")
   720      9065   61409000.0   6774.3      0.2      if Calc_Inds.shape[0] > 0:
   721                                                   # Retrieve the Max_Ent, Min_x, Max_X and observed overlap values
   722                                                   Min_Overlap = QFMs[Calc_Inds] - RFms[Calc_Inds]
   723                                                   Max_Overlap = np.minimum(QFMs[Calc_Inds], RFMs[Calc_Inds])
   724                                                   Overlaps = All_Overlaps_Options[Use_Curve, Calc_Inds]
   725                                                   Max_Ent_x = Max_Ent_Options[Use_Curve, Calc_Inds]
   726                                                   Ind_X_1 = Max_Ent_x - Min_Overlap
   727                                                   Ind_X1 = Max_Overlap - Max_Ent_x
   728                                                   #
   729                                                   SD_1_Inds = np.where(Overlaps < Max_Ent_x)[0]
   730                                                   # NOTE: USE ~
   731                                                   SD1_Inds = np.where(Overlaps >= Max_Ent_x)[0]
   732                                                   SDs = np.zeros(Calc_Inds.shape[0]) - 1
   733                                                   SDs[SD1_Inds] = 1
   734                                                   #
   735                                                   D = np.zeros(Calc_Inds.shape[0])
   736                                                   O = np.zeros(Calc_Inds.shape[0])
   737                                                   D[SD_1_Inds] = Overlaps[SD_1_Inds] - (
   738                                                       Sample_Cardinality
   739                                                       - (QFms[Calc_Inds][SD_1_Inds] + RFms[Calc_Inds][SD_1_Inds])
   740                                                   )
   741                                                   O[SD_1_Inds] = Overlaps[SD_1_Inds]
   742                                                   D[SD1_Inds] = QFMs[Calc_Inds][SD1_Inds] - Overlaps[SD1_Inds]
   743                                                   O[SD1_Inds] = (
   744                                                       RFMs[Calc_Inds][SD1_Inds] - QFMs[Calc_Inds][SD1_Inds] + D[SD1_Inds]
   745                                                   )
   746                                                   # Perform caclulations with ESE (4)
   747                                                   CE, Ind_E, Min_E = ESE4(
   748                                                       Overlaps,
   749                                                       SDs,
   750                                                       RFms[Calc_Inds],
   751                                                       RFMs[Calc_Inds],
   752                                                       QFms[Calc_Inds],
   753                                                       QFMs[Calc_Inds],
   754                                                       Sample_Cardinality,
   755                                                       Min_Overlap,
   756                                                       Max_Overlap,
   757                                                   )
   758                                                   #
   759                                                   SWs = (Ind_E - Min_E) / Ind_E
   760                                                   SGs = (Ind_E - CE) / (Ind_E - Min_E)
   761                                                   # Because of float errors the following inequality at the boundary sometimes fails, (CE[Test] < Min_E[Test]), leading to values greater than 1. It is valid to just correct them to 1.
   762                                                   # NOTE: USE NP.CLIP
   763                                                   SGs[SGs > 1] = 1
   764                                                   # Because of float errors the following inequality at the maximum sometimes fails, (CE[Test] > Ind_E[Test]), leading to values greater than less than 0. It is valid to just correct them to 0.
   765                                                   SGs[SGs < 0] = 0
   766                                                   #
   767                                                   ESS = SWs * SGs * SDs * All_Use_Cases[Use_Curve, Calc_Inds]
   768                                                   All_ESSs[Use_Curve, Calc_Inds] = ESS
   769                                                   All_SWs[Use_Curve, Calc_Inds] = SWs
   770                                                   All_SGs[Use_Curve, Calc_Inds] = SGs
   771                                                   #
   772                                                   SD_1_IndEnt = Ind_E[SD_1_Inds] / Ind_X_1[SD_1_Inds]
   773                                                   SD1_IndEnt = Ind_E[SD1_Inds] / Ind_X1[SD1_Inds]
   774                                                   #
   775                                                   D_EPs = np.zeros(Ind_E.shape[0])
   776                                                   D_EPs[SD_1_Inds] = (
   777                                                       (CE[SD_1_Inds] - Min_E[SD_1_Inds]) / D[SD_1_Inds]
   778                                                   ) - SD_1_IndEnt
   779                                                   D_EPs[SD1_Inds] = ((CE[SD1_Inds] - Min_E[SD1_Inds]) / D[SD1_Inds]) - SD1_IndEnt
   780                                                   #
   781                                                   O_EPs = np.zeros(Ind_E.shape[0])
   782                                                   O_EPs[SD_1_Inds] = ((CE[SD_1_Inds]) / O[SD_1_Inds]) - SD_1_IndEnt
   783                                                   O_EPs[SD1_Inds] = ((CE[SD1_Inds]) / O[SD1_Inds]) - SD1_IndEnt
   784                                                   #
   785                                                   All_D_EPs[Use_Curve, Calc_Inds] = D_EPs
   786                                                   All_O_EPs[Use_Curve, Calc_Inds] = O_EPs
   787                                                   #
   788                                               ########
   789                                               ## For each feature pair, accept the orientation with the maximum ESS as it is the least likely to have occoured by chance.
   790      9065 1696568000.0 187155.9      6.3      Max_ESS_Inds = np.nanargmax(np.absolute(All_ESSs), axis=0)
   791                                               ## Return results
   792      9065   31338000.0   3457.0      0.1      return (
   793      9065  404909000.0  44667.3      1.5          All_ESSs[Max_ESS_Inds, np.arange(RFms.shape[0])],
   794      9065  395139000.0  43589.5      1.5          All_D_EPs[Max_ESS_Inds, np.arange(RFms.shape[0])],
   795      9065  410869000.0  45324.8      1.5          All_O_EPs[Max_ESS_Inds, np.arange(RFms.shape[0])],
   796      9065  382955000.0  42245.4      1.4          All_SWs[Max_ESS_Inds, np.arange(RFms.shape[0])],
   797      9065  347127000.0  38293.1      1.3          All_SGs[Max_ESS_Inds, np.arange(RFms.shape[0])],
   798                                               )

Total time: 171.628 s
File: /Users/shandc/Documents/ESFS/ESFS/ESFS.py
Function: Get_Overlap_Info at line 324

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   324                                           @profile
   325                                           def Get_Overlap_Info(
   326                                               Fixed_Feature,
   327                                               Fixed_Feature_Cardinality,
   328                                               Sample_Cardinality,
   329                                               Feature_Sums,
   330                                               FF_QF_Vs_RF,
   331                                           ):
   332                                               """
   333                                               For any pair of features the ES mathematical framework has a set of logical rules regarding how the ES metrics
   334                                               should be calcualted. These logical rules dictate which of the two features is the reference feature (RF) or query feature
   335                                               (QF) and which of the 4 Entropy Sort Equations (ESE 1-4) should be used (Add reference to supplemental figure of
   336                                               new manuscript when ready).
   337                                               """
   338                                               ## Set up an array to track which of ESE equations 1-4 the recorded observed overlap relates to (row), and if it is
   339                                               # native correlation (1) or flipped anti-correlation (-1). Row 1 = mm, row 2 = Mm, row 3 = mM, row 4 = MM.
   340      9065   25762000.0   2841.9      0.0      All_Use_Cases = np.zeros((4, Feature_Sums.shape[0]))
   341                                               ## Set up an array to track the observed overlaps between the FF and the secondary features.
   342      9065   26053000.0   2874.0      0.0      All_Overlaps_Options = np.zeros((4, Feature_Sums.shape[0]))
   343                                               ## Set up a list to track the used inds/features for each ESE
   344      9065    4831000.0    532.9      0.0      All_Used_Inds = [[]] * 4
   345                                               ####
   346                                               ## Pairwise calculate total overlaps of FF values with the values every other a feature in adata
   347      9065   52621000.0   5804.9      0.0      Non_Zero_Inds = np.where(Fixed_Feature != 0)[0]
   348      9065        5e+10    5e+06     27.8      Sub_Global_Scaled_Matrix = Global_Scaled_Matrix[Non_Zero_Inds, :]
   349     18130  807349000.0  44531.1      0.5      B = csc_matrix(
   350      9065    1443000.0    159.2      0.0          (
   351      9065 7854098000.0 866420.1      4.6              Fixed_Feature[Non_Zero_Inds].T[0][Sub_Global_Scaled_Matrix.indices],
   352      9065    2126000.0    234.5      0.0              Sub_Global_Scaled_Matrix.indices,
   353      9065    1733000.0    191.2      0.0              Sub_Global_Scaled_Matrix.indptr,
   354                                                   )
   355                                               )
   356      9065        2e+10    2e+06     11.3      Overlaps = Sub_Global_Scaled_Matrix.minimum(B).sum(axis=0).A[0]
   357                                               ## Pairwise calculate total overlaps of Inverse FF values with the values every other a feature in adata
   358      9065   41542000.0   4582.7      0.0      Inverse_Fixed_Feature = 1 - Fixed_Feature  # np.max(Fixed_Feature) - Fixed_Feature
   359      9065   61779000.0   6815.1      0.0      Non_Zero_Inds = np.where(Inverse_Fixed_Feature != 0)[0]
   360      9065        3e+10    4e+06     20.3      Sub_Global_Scaled_Matrix = Global_Scaled_Matrix[Non_Zero_Inds, :]
   361     18130 1577356000.0  87002.5      0.9      B = csc_matrix(
   362      9065    1956000.0    215.8      0.0          (
   363      9065        2e+10    2e+06     10.2              Inverse_Fixed_Feature[Non_Zero_Inds].T[0][Sub_Global_Scaled_Matrix.indices],
   364      9065    2664000.0    293.9      0.0              Sub_Global_Scaled_Matrix.indices,
   365      9065    2779000.0    306.6      0.0              Sub_Global_Scaled_Matrix.indptr,
   366                                                   )
   367                                               )
   368      9065        4e+10    4e+06     23.1      Inverse_Overlaps = Sub_Global_Scaled_Matrix.minimum(B).sum(axis=0).A[0]
   369                                               ####
   370                                               ### Using the logical rules of ES to work out which ESE should be used for each pair of features beign compared.
   371                                               ## If FF is observed in it's minority state, use the following 4 steps to caclulate overlaps with every other feature
   372      9065   43790000.0   4830.7      0.0      if Fixed_Feature_Cardinality < (Sample_Cardinality / 2):
   373                                                   #######
   374                                                   ## FF and other feature are minority states & FF is QF
   375     27195   90651000.0   3333.4      0.1          Calc_Inds = np.where(
   376      9065  123861000.0  13663.7      0.1              (Feature_Sums < (Sample_Cardinality / 2)) & (FF_QF_Vs_RF == 1)
   377      9065    1474000.0    162.6      0.0          )[0]
   378                                                   ## Track which features are observed as mm (row 1), and which are mM when the secondary feature is flipped (row 3)
   379      9065  361162000.0  39841.4      0.2          All_Use_Cases[:, Calc_Inds] = np.array([1, -1, 0, 0]).reshape(4, 1)
   380                                                   ## Calcualte the overlaps as the sum of minimums between samples, using Global_Scaled_Matrix for natural observations
   381                                                   # and Global_Scaled_Matrix_Inverse for inverse observations.
   382      9065  136795000.0  15090.5      0.1          All_Overlaps_Options[0, Calc_Inds] = Overlaps[Calc_Inds]  # Overlaps_mm
   383      9065   87710000.0   9675.7      0.1          All_Used_Inds[0] = np.append(All_Used_Inds[0], Calc_Inds)
   384      9065  113728000.0  12545.8      0.1          All_Overlaps_Options[1, Calc_Inds] = Inverse_Overlaps[Calc_Inds]  # Overlaps_Mm
   385      9065   39340000.0   4339.8      0.0          All_Used_Inds[1] = np.append(All_Used_Inds[1], Calc_Inds)
   386                                                   #######
   387                                                   ## FF and other feature are minority states & FF is RF
   388     27195   80160000.0   2947.6      0.0          Calc_Inds = np.where(
   389      9065   57295000.0   6320.5      0.0              (Feature_Sums < (Sample_Cardinality / 2)) & (FF_QF_Vs_RF == 0)
   390      9065    1331000.0    146.8      0.0          )[0]
   391                                                   ## Track which features are observed as mm (row 1), and which are Mm when the secondary feature is flipped (row 2)
   392      9065  339008000.0  37397.5      0.2          All_Use_Cases[:, Calc_Inds] = np.array([1, 0, -1, 0]).reshape(4, 1)
   393                                                   ## Calcualte the overlaps as the sum of minimums between samples, using Global_Scaled_Matrix for natural observations
   394                                                   # and Global_Scaled_Matrix_Inverse for inverse observations.
   395      9065  133565000.0  14734.1      0.1          All_Overlaps_Options[0, Calc_Inds] = Overlaps[Calc_Inds]  # Overlaps_mm
   396      9065   48073000.0   5303.1      0.0          All_Used_Inds[0] = np.append(All_Used_Inds[0], Calc_Inds)
   397      9065  114042000.0  12580.5      0.1          All_Overlaps_Options[2, Calc_Inds] = Inverse_Overlaps[Calc_Inds]  # Overlaps_mM
   398      9065   40876000.0   4509.2      0.0          All_Used_Inds[2] = np.append(All_Used_Inds[2], Calc_Inds)
   399                                                   #######
   400                                                   ## FF is minority, other feature is majority & FF is QF
   401     27195   23413000.0    860.9      0.0          Calc_Inds = np.where(
   402      9065   54933000.0   6059.9      0.0              (Feature_Sums >= (Sample_Cardinality / 2)) & (FF_QF_Vs_RF == 1)
   403      9065    1159000.0    127.9      0.0          )[0]
   404                                                   ## Track which features are observed as mM (row 4), and which are mm when the secondary feature is flipped (row 1)
   405      9065   22323000.0   2462.5      0.0          All_Use_Cases[:, Calc_Inds] = np.array([0, 0, 1, -1]).reshape(4, 1)
   406                                                   ## Calcualte the overlaps as the sum of minimums between samples, using Global_Scaled_Matrix for natural observations
   407                                                   # and Global_Scaled_Matrix_Inverse for inverse observations.
   408      9065   11873000.0   1309.8      0.0          All_Overlaps_Options[3, Calc_Inds] = Inverse_Overlaps[Calc_Inds]  # Overlaps_MM
   409      9065   28734000.0   3169.8      0.0          All_Used_Inds[3] = np.append(All_Used_Inds[3], Calc_Inds)
   410      9065    8244000.0    909.4      0.0          All_Overlaps_Options[2, Calc_Inds] = Overlaps[Calc_Inds]  # Overlaps_mM
   411      9065   30426000.0   3356.4      0.0          All_Used_Inds[2] = np.append(All_Used_Inds[2], Calc_Inds)
   412                                                   #######
   413                                                   ## FF is minority, other feature is majority & FF is RF
   414     27195   22146000.0    814.3      0.0          Calc_Inds = np.where(
   415      9065   44388000.0   4896.6      0.0              (Feature_Sums >= (Sample_Cardinality / 2)) & (FF_QF_Vs_RF == 0)
   416      9065    1235000.0    136.2      0.0          )[0]
   417                                                   ## Track which features are observed as Mm (row 2), and which are mm when the secondary feature is flipped (row 1)
   418      9065   17557000.0   1936.8      0.0          All_Use_Cases[:, Calc_Inds] = np.array([0, 1, 0, -1]).reshape(4, 1)
   419                                                   ## Calcualte the overlaps as the sum of minimums between samples, using Global_Scaled_Matrix for natural observations
   420                                                   # and Global_Scaled_Matrix_Inverse for inverse observations.
   421      9065    9929000.0   1095.3      0.0          All_Overlaps_Options[3, Calc_Inds] = Inverse_Overlaps[Calc_Inds]  # Overlaps_MM
   422      9065   23403000.0   2581.7      0.0          All_Used_Inds[3] = np.append(All_Used_Inds[3], Calc_Inds)
   423      9065    9412000.0   1038.3      0.0          All_Overlaps_Options[1, Calc_Inds] = Overlaps[Calc_Inds]  # Overlaps_Mm
   424      9065   33506000.0   3696.2      0.0          All_Used_Inds[1] = np.append(All_Used_Inds[1], Calc_Inds)
   425                                                   #
   426                                               ## If FF is observed in it's majority state, use the following 4 steps to caclulate overlaps with every other feature
   427      9065   18476000.0   2038.2      0.0      if Fixed_Feature_Cardinality >= (Sample_Cardinality / 2):
   428                                                   #######
   429                                                   ## FF is majority, other feature is minority & FF is QF
   430                                                   Calc_Inds = np.where(
   431                                                       (Feature_Sums < (Sample_Cardinality / 2)) & (FF_QF_Vs_RF == 1)
   432                                                   )[0]
   433                                                   ## Track which features are observed as Mm (row 2), and which are MM when the secondary feature is flipped (row 4)
   434                                                   All_Use_Cases[:, Calc_Inds] = np.array([-1, 1, 0, 0]).reshape(4, 1)
   435                                                   ## Calcualte the overlaps as the sum of minimums between samples, using Global_Scaled_Matrix for natural observations
   436                                                   # and Global_Scaled_Matrix_Inverse for inverse observations.
   437                                                   All_Overlaps_Options[1, Calc_Inds] = Overlaps[Calc_Inds]  # Overlaps_Mm
   438                                                   All_Used_Inds[1] = np.append(All_Used_Inds[1], Calc_Inds)
   439                                                   All_Overlaps_Options[0, Calc_Inds] = Inverse_Overlaps[Calc_Inds]  # Overlaps_mm
   440                                                   All_Used_Inds[0] = np.append(All_Used_Inds[0], Calc_Inds)
   441                                                   #######
   442                                                   ## FF is majority, other feature is minority & FF is RF
   443                                                   Calc_Inds = np.where(
   444                                                       (Feature_Sums < (Sample_Cardinality / 2)) & (FF_QF_Vs_RF == 0)
   445                                                   )[0]
   446                                                   ## Track which features are observed as mM (row 3), and which are MM when the secondary feature is flipped (row 4)
   447                                                   All_Use_Cases[:, Calc_Inds] = np.array([-1, 0, 1, 0]).reshape(4, 1)
   448                                                   ## Calcualte the overlaps as the sum of minimums between samples, using Global_Scaled_Matrix for natural observations
   449                                                   # and Global_Scaled_Matrix_Inverse for inverse observations.
   450                                                   All_Overlaps_Options[2, Calc_Inds] = Overlaps[Calc_Inds]  # Overlaps_mM
   451                                                   All_Used_Inds[2] = np.append(All_Used_Inds[2], Calc_Inds)
   452                                                   All_Overlaps_Options[0, Calc_Inds] = Inverse_Overlaps[Calc_Inds]  # Overlaps_mm
   453                                                   All_Used_Inds[0] = np.append(All_Used_Inds[0], Calc_Inds)
   454                                                   #######
   455                                                   ## FF is majority, other feature is majority & FF is QF
   456                                                   Calc_Inds = np.where(
   457                                                       (Feature_Sums >= (Sample_Cardinality / 2)) & (FF_QF_Vs_RF == 1)
   458                                                   )[0]
   459                                                   ## Track which features are observed as MM (row 4), and which are Mm when the secondary feature is flipped (row 2)
   460                                                   All_Use_Cases[:, Calc_Inds] = np.array([0, 0, -1, 1]).reshape(4, 1)
   461                                                   ## Calcualte the overlaps as the sum of minimums between samples, using Global_Scaled_Matrix for natural observations
   462                                                   # and Global_Scaled_Matrix_Inverse for inverse observations.
   463                                                   All_Overlaps_Options[2, Calc_Inds] = Inverse_Overlaps[Calc_Inds]  # Overlaps_mM
   464                                                   All_Used_Inds[2] = np.append(All_Used_Inds[2], Calc_Inds)
   465                                                   All_Overlaps_Options[3, Calc_Inds] = Overlaps[Calc_Inds]  # Overlaps_MM
   466                                                   All_Used_Inds[3] = np.append(All_Used_Inds[3], Calc_Inds)
   467                                                   #######
   468                                                   ## FF is majority, other feature is majority & FF is RF
   469                                                   Calc_Inds = np.where(
   470                                                       (Feature_Sums >= (Sample_Cardinality / 2)) & (FF_QF_Vs_RF == 0)
   471                                                   )[0]
   472                                                   ## Track which features are observed as MM (row 4), and which are mM when the secondary feature is flipped (row 3)
   473                                                   All_Use_Cases[:, Calc_Inds] = np.array([0, -1, 0, 1]).reshape(4, 1)
   474                                                   ## Calcualte the overlaps as the sum of minimums between samples, using Global_Scaled_Matrix for natural observations
   475                                                   # and Global_Scaled_Matrix_Inverse for inverse observations.
   476                                                   All_Overlaps_Options[1, Calc_Inds] = Inverse_Overlaps[Calc_Inds]  # Overlaps_Mm
   477                                                   All_Used_Inds[1] = np.append(All_Used_Inds[1], Calc_Inds)
   478                                                   All_Overlaps_Options[3, Calc_Inds] = Overlaps[Calc_Inds]  # Overlaps_MM
   479                                                   All_Used_Inds[3] = np.append(All_Used_Inds[3], Calc_Inds)
   480                                                   #
   481      9065   25849000.0   2851.5      0.0      return All_Use_Cases, All_Overlaps_Options, All_Used_Inds

Total time: 203.812 s
File: /Users/shandc/Documents/ESFS/ESFS/ESFS.py
Function: Calc_ES_Metrics at line 259

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   259                                           @profile
   260                                           def Calc_ES_Metrics(Feature_Ind, Sample_Cardinality, Feature_Sums, Minority_States):
   261                                               """
   262                                               This function calcualtes the ES metrics for one of the features in the Secondary_Features object against
   263                                               every variable/feature in the adata object.
   264                                           
   265                                               Feature_Ind - Indicates the column of Secondary_Features being used.
   266                                               Sample_Cardinality - Inherited scalar of the number of samples in adata.
   267                                               Feature_Sums - Inherited vector of the columns sums of adata.
   268                                               Minority_States - Inherited vector of the minority state sums of each column of adata.
   269                                               """
   270                                               ## Extract the Fixed Feature (FF)
   271      9065 1501173000.0 165601.0      0.7      Fixed_Feature = Secondary_Features[:, Feature_Ind].A
   272      9065   74914000.0   8264.1      0.0      Fixed_Feature_Cardinality = np.sum(Fixed_Feature)
   273      9065    1953000.0    215.4      0.0      Fixed_Feature_Minority_State = Fixed_Feature_Cardinality
   274      9065   17214000.0   1899.0      0.0      if Fixed_Feature_Minority_State >= (Sample_Cardinality / 2):
   275                                                   Fixed_Feature_Minority_State = Sample_Cardinality - Fixed_Feature_Minority_State
   276                                               ## Identify where FF is the QF or RF
   277      9065   14546000.0   1604.6      0.0      FF_QF_Vs_RF = np.zeros(Feature_Sums.shape[0])
   278      9065  145287000.0  16027.2      0.1      FF_QF_Vs_RF[np.where(Fixed_Feature_Minority_State > Minority_States)[0]] = (
   279      9065    4454000.0    491.3      0.0          1  # 1's mean FF is QF
   280                                               )
   281                                               ##Caclulate the QFms, RFms, RFMs and QFMs for each FF and secondary feature pair
   282      9065   13956000.0   1539.5      0.0      RFms = Minority_States.copy()
   283      9065   89081000.0   9826.9      0.0      Switch = np.where(FF_QF_Vs_RF == 0)[0]
   284      9065   49282000.0   5436.5      0.0      RFms[Switch] = Fixed_Feature_Minority_State
   285      9065   27300000.0   3011.6      0.0      RFMs = Sample_Cardinality - RFms
   286      9065   12659000.0   1396.5      0.0      QFms = Minority_States.copy()
   287      9065   89523000.0   9875.7      0.0      Switch = np.where(FF_QF_Vs_RF == 1)[0]
   288      9065   45307000.0   4998.0      0.0      QFms[Switch] = Fixed_Feature_Minority_State
   289      9065   19934000.0   2199.0      0.0      QFMs = Sample_Cardinality - QFms
   290                                               ## Calculate the values of (x) that correspond to the maximum for each overlap scenario (mm, Mm, mM and MM) (m = minority, M = majority)
   291      9065   56207000.0   6200.4      0.0      Max_Ent_x_mm = (RFms * QFms) / (RFms + RFMs)
   292      9065   49850000.0   5499.2      0.0      Max_Ent_x_Mm = (QFMs * RFms) / (RFms + RFMs)
   293      9065   46373000.0   5115.6      0.0      Max_Ent_x_mM = (RFMs * QFms) / (RFms + RFMs)
   294      9065   46575000.0   5137.9      0.0      Max_Ent_x_MM = (RFMs * QFMs) / (RFms + RFMs)
   295      9065   47117000.0   5197.7      0.0      Max_Ent_Options = np.array([Max_Ent_x_mm, Max_Ent_x_Mm, Max_Ent_x_mM, Max_Ent_x_MM])
   296                                               ######
   297                                               ## Caclulate the overlap between the FF states and the secondary features, using the correct ESE (1-4)
   298     18130        2e+11    1e+07     85.1      All_Use_Cases, All_Overlaps_Options, All_Used_Inds = Get_Overlap_Info(
   299      9065    1869000.0    206.2      0.0          Fixed_Feature,
   300      9065     945000.0    104.2      0.0          Fixed_Feature_Cardinality,
   301      9065    2084000.0    229.9      0.0          Sample_Cardinality,
   302      9065    1104000.0    121.8      0.0          Feature_Sums,
   303      9065     797000.0     87.9      0.0          FF_QF_Vs_RF,
   304                                               )
   305                                               ## Having extracted the overlaps and their respective ESEs (1-4), calcualte the ESS and EPs
   306     18130        3e+10    2e+06     13.5      ESSs, D_EPs, O_EPs, SWs, SGs = Calc_ESSs(
   307      9065    1621000.0    178.8      0.0          RFms,
   308      9065    1446000.0    159.5      0.0          QFms,
   309      9065    1405000.0    155.0      0.0          RFMs,
   310      9065    1573000.0    173.5      0.0          QFMs,
   311      9065    2006000.0    221.3      0.0          Max_Ent_Options,
   312      9065    1144000.0    126.2      0.0          Sample_Cardinality,
   313      9065    2894000.0    319.2      0.0          All_Overlaps_Options,
   314      9065    3460000.0    381.7      0.0          All_Use_Cases,
   315      9065    1109000.0    122.3      0.0          All_Used_Inds,
   316                                               )
   317      9065   52557000.0   5797.8      0.0      Identical_Features = np.where(ESSs == 1)[0]
   318      9065    5087000.0    561.2      0.0      D_EPs[Identical_Features] = 0
   319      9065    4368000.0    481.9      0.0      O_EPs[Identical_Features] = 0
   320      9065  426133000.0  47008.6      0.2      EPs = nanmaximum(D_EPs, O_EPs)
   321      9065   11482000.0   1266.6      0.0      return ESSs, EPs, SWs, SGs

Total time: 217.655 s
File: /Users/shandc/Documents/ESFS/ESFS/ESFS.py
Function: Parallel_Calc_ES_Matricies at line 75

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    75                                           @profile
    76                                           def Parallel_Calc_ES_Matricies(
    77                                               adata,
    78                                               Secondary_Features_Label="Self",
    79                                               save_matrices=np.array(["ESSs", "EPs"]),
    80                                               Use_Cores=-1,
    81                                           ):
    82                                               """
    83                                               Using the Entropy Sorting (ES) mathematical framework, we may caclulate the ESS, EP, SW and SG correlation metrics
    84                                               outlined in Radley et al. 2023.
    85                                           
    86                                               This function assumes that the user aims has a set of input features (Secondary_Features_Label) that will be used to pairwise calculate ES metrics
    87                                               against each variable (column) of the provided anndata object. When Secondary_Features_Label is left blank, it defaults
    88                                               to "Self" meaning ES metrics will be calcualted pairwise between all of the variables in adata. If Secondary_Features_Label
    89                                               is not "Self", the user must point the algorithm to an attribute of adata that contains an array with the same number of samples
    90                                               as adata and a set of secondary features (columns).
    91                                           
    92                                               save_matrices disctates which ES metrics will be written to the outputted adata object. The options are "ESSs", "EPs", "SGs", "SWs".
    93                                           
    94                                               Use_Cores defines how many CPU cores to use. Is Use_Cores = -1, the software will use N-1 the number of cores available on the machine.
    95                                               """
    96                                               ## Establish which Secondary_Features will be compared against each of the features in adata
    97                                               global Secondary_Features
    98         1       1000.0   1000.0      0.0      if Secondary_Features_Label == "Self":
    99         1    1911000.0    2e+06      0.0          Secondary_Features = adata.layers["Scaled_Counts"].copy()
   100                                               else:
   101                                                   print(
   102                                                       "You have provided a 'Secondary_Features_Label', implying that in the anndata object there is a corresponding csc_sparse martix object with rows as samples and columns as features. Each feature will be used to calculate ES scores for each of the variables of the adata object"
   103                                                   )
   104                                                   Secondary_Features = adata.obsm[Secondary_Features_Label]
   105                                               #
   106                                               ## Create the global Global_Scaled_Matrix array for faster parallel computing calculations
   107                                               global Global_Scaled_Matrix
   108         1      16000.0  16000.0      0.0      Global_Scaled_Matrix = adata.layers["Scaled_Counts"]
   109                                               ## Extract sample and feature cardinality
   110         1          0.0      0.0      0.0      Sample_Cardinality = Global_Scaled_Matrix.shape[0]
   111                                               ## Calculate feature sums and minority states for each adata feature
   112         1     601000.0 601000.0      0.0      Feature_Sums = Global_Scaled_Matrix.sum(axis=0).A[0]
   113         1       2000.0   2000.0      0.0      Minority_States = Feature_Sums.copy()
   114         1       9000.0   9000.0      0.0      Switch = np.where(Minority_States >= (Sample_Cardinality / 2))[0]
   115         1       3000.0   3000.0      0.0      Minority_States[Switch] = Sample_Cardinality - Minority_States[Switch]
   116                                               ####
   117                                               ## Provide indicies for parallel computing.
   118         1       4000.0   4000.0      0.0      Feature_Inds = np.arange(Secondary_Features.shape[1])
   119                                               ## Identify number of cores to use.
   120         1      19000.0  19000.0      0.0      Cores_Available = multiprocess.cpu_count()
   121         1      11000.0  11000.0      0.0      print("Cores Available: " + str(Cores_Available))
   122         1          0.0      0.0      0.0      if Use_Cores == -1:
   123                                                   Use_Cores = (
   124                                                       Cores_Available - 1
   125                                                   )  # -1 Is an arbitrary buffer of idle cores that I set.
   126                                                   if Use_Cores < 1:
   127                                                       Use_Cores = 1
   128         1       2000.0   2000.0      0.0      print("Cores Used: " + str(Use_Cores))
   129                                               ## Perform calculations
   130         1       1000.0   1000.0      0.0      print("Calculating ESS and EP matricies.")
   131         2       2000.0   1000.0      0.0      print(
   132         1          0.0      0.0      0.0          "If progress bar freezes consider increasing system memory or reducing number of cores used with the 'Use_Cores' parameter as you may have hit a memory ceiling for your machine."
   133                                               )
   134                                               # if __name__ == '__main__':
   135                                               ## Parallel compute
   136         2     262000.0 131000.0      0.0      with np.errstate(divide="ignore", invalid="ignore"):
   137         1          0.0      0.0      0.0          if Use_Cores == 1:
   138                                                       # If only one core is used, use the standard map function
   139         2        2e+11    1e+11     93.8              Results = list(
   140         2       1000.0    500.0      0.0                  map(
   141         2       1000.0    500.0      0.0                      partial(
   142         1          0.0      0.0      0.0                          Calc_ES_Metrics,
   143         1          0.0      0.0      0.0                          Sample_Cardinality=Sample_Cardinality,
   144         1          0.0      0.0      0.0                          Feature_Sums=Feature_Sums,
   145         1          0.0      0.0      0.0                          Minority_States=Minority_States,
   146                                                               ),
   147         1          0.0      0.0      0.0                      Feature_Inds,
   148                                                           )
   149                                                       )
   150                                                   else:
   151                                                       Results = p_map(
   152                                                           partial(
   153                                                               Calc_ES_Metrics,
   154                                                               Sample_Cardinality=Sample_Cardinality,
   155                                                               Feature_Sums=Feature_Sums,
   156                                                               Minority_States=Minority_States,
   157                                                           ),
   158                                                           Feature_Inds,
   159                                                           num_cpus=Use_Cores,
   160                                                       )
   161                                               ## Unpack results
   162         1 6291321000.0    6e+09      2.9      Results = np.asarray(Results)
   163                                               ## Save outputs requested by the save_matrices paramater
   164         1    2546000.0    3e+06      0.0      if np.isin("ESSs", save_matrices):
   165         1       2000.0   2000.0      0.0          ESSs = Results[:, 0, :]
   166                                                   if (
   167         1       1000.0   1000.0      0.0              Secondary_Features_Label == "Self"
   168                                                   ):  ## The vast majority of outputs are symmetric, but float errors appear to make some non-symmetric. If we can fix this that could be cool.
   169         1 3306519000.0    3e+09      1.5              ESSs = nanmaximum(ESSs, ESSs.T)
   170                                                   #
   171                                                   # Label_ESSs = pd.DataFrame(ESSs.T,columns=Fixed_Features.index,index=adata.var.index.tolist())
   172         1   15547000.0    2e+07      0.0          adata.varm[Secondary_Features_Label + "_ESSs"] = ESSs.T
   173         2     193000.0  96500.0      0.0          print(
   174         6     141000.0  23500.0      0.0              "ESSs for "
   175         1          0.0      0.0      0.0              + Secondary_Features_Label
   176         1       2000.0   2000.0      0.0              + " label have been saved to "
   177         1          0.0      0.0      0.0              + "'adata.varm['"
   178         1          0.0      0.0      0.0              + Secondary_Features_Label
   179         1          0.0      0.0      0.0              + "_ESSs']'"
   180                                                   )
   181                                                   #
   182         1     252000.0 252000.0      0.0      if np.isin("EPs", save_matrices):
   183         1      10000.0  10000.0      0.0          EPs = Results[:, 1, :]
   184         1          0.0      0.0      0.0          if Secondary_Features_Label == "Self":
   185         1 3926840000.0    4e+09      1.8              EPs = nanmaximum(EPs, EPs.T)
   186                                                   #
   187                                                   # Label_EPs = pd.DataFrame(EPs.T,columns=Fixed_Features.index,index=adata.var.index.tolist())
   188         1    1180000.0    1e+06      0.0          adata.varm[Secondary_Features_Label + "_EPs"] = EPs.T
   189         2      59000.0  29500.0      0.0          print(
   190         6      14000.0   2333.3      0.0              "EPs for "
   191         1          0.0      0.0      0.0              + Secondary_Features_Label
   192         1       4000.0   4000.0      0.0              + " label have been saved to "
   193         1       1000.0   1000.0      0.0              + "'adata.varm['"
   194         1          0.0      0.0      0.0              + Secondary_Features_Label
   195         1       4000.0   4000.0      0.0              + "_EPs']'"
   196                                                   )
   197                                                   #
   198         1     350000.0 350000.0      0.0      if np.isin("SWs", save_matrices):
   199                                                   SWs = Results[:, 2, :]
   200                                                   if Secondary_Features_Label == "Self":
   201                                                       SWs = nanmaximum(SWs, SWs.T)
   202                                                   #
   203                                                   # Label_SWs = pd.DataFrame(SWs.T,columns=Fixed_Features.index,index=adata.var.index.tolist())
   204                                                   adata.varm[Secondary_Features_Label + "_SWs"] = SWs.T
   205                                                   print(
   206                                                       "SWs for "
   207                                                       + Secondary_Features_Label
   208                                                       + " label have been saved to "
   209                                                       + "'adata.varm['"
   210                                                       + Secondary_Features_Label
   211                                                       + "_SWs']'"
   212                                                   )
   213                                                   #
   214         1      42000.0  42000.0      0.0      if np.isin("SGs", save_matrices):
   215                                                   SGs = Results[:, 3, :]
   216                                                   if Secondary_Features_Label == "Self":
   217                                                       SGs = nanmaximum(SGs, SGs.T)
   218                                                   #
   219                                                   # Label_SGs = pd.DataFrame(SGs.T,columns=Fixed_Features.index,index=adata.var.index.tolist())
   220                                                   adata.varm[Secondary_Features_Label + "_SGs"] = SGs.T
   221                                                   print(
   222                                                       "SGs for "
   223                                                       + Secondary_Features_Label
   224                                                       + " label have been saved to "
   225                                                       + "'adata.varm['"
   226                                                       + Secondary_Features_Label
   227                                                       + "_SGs']'"
   228                                                   )
   229                                                   #
   230         1       4000.0   4000.0      0.0      return adata

  0.15 seconds - /Users/shandc/Documents/ESFS/ESFS/ESFS.py:38 - Create_Scaled_Matrix
  2.69 seconds - /Users/shandc/Documents/ESFS/ESFS/ESFS.py:853 - ESE2
  2.72 seconds - /Users/shandc/Documents/ESFS/ESFS/ESFS.py:909 - ESE3
  5.56 seconds - /Users/shandc/Documents/ESFS/ESFS/ESFS.py:801 - ESE1
  7.32 seconds - /Users/shandc/Documents/ESFS/ESFS/ESFS.py:233 - nanmaximum
 27.00 seconds - /Users/shandc/Documents/ESFS/ESFS/ESFS.py:484 - Calc_ESSs
171.63 seconds - /Users/shandc/Documents/ESFS/ESFS/ESFS.py:324 - Get_Overlap_Info
203.81 seconds - /Users/shandc/Documents/ESFS/ESFS/ESFS.py:259 - Calc_ES_Metrics
217.65 seconds - /Users/shandc/Documents/ESFS/ESFS/ESFS.py:75 - Parallel_Calc_ES_Matricies
